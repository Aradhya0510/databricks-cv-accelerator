# Model Configuration for SegFormer Segmentation
model:
  model_name: "nvidia/segformer-b0-finetuned-ade-512-512"  # SegFormer base model
  task_type: "segmentation"
  segmentation_type: "semantic"  # "semantic", "instance", or "panoptic"
  num_classes: 150  # ADE20K dataset has 150 classes
  pretrained: true
  learning_rate: 1e-4
  weight_decay: 0.01
  scheduler: "cosine"
  epochs: 50
  image_size: 512  # SegFormer default image size
  class_names: null  # Will be loaded from dataset
  model_kwargs: {}  # Additional model arguments

# Data Configuration
data:
  # Separate paths for train/val/test splits
  train_data_path: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/images/"
  train_annotation_file: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/annotations_train.json"
  val_data_path: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/images/"
  val_annotation_file: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/annotations_val.json"
  test_data_path: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/images/"
  test_annotation_file: "/Volumes/<catalog>/<schema>/<volume>/<path>/data/annotations_test.json"
  
  # Data loading parameters
  batch_size: 8  # SegFormer recommended batch size per GPU
  num_workers: 4
  model_name: "nvidia/segformer-b0-finetuned-ade-512-512"  # Required for adapter initialization
  
  # Image processing
  image_size: 512  # [height, width]
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet normalization
  normalize_std: [0.229, 0.224, 0.225]
  
  # Data augmentation
  horizontal_flip: true
  vertical_flip: false
  rotation: 30  # degrees
  brightness_contrast: 0.2
  hue_saturation: 0.2

# Training Configuration
training:
  # Basic training parameters
  max_epochs: 50  # SegFormer default training epochs
  
  # Learning rate and optimization
  learning_rate: 1e-4
  weight_decay: 0.01
  scheduler: "cosine"
  scheduler_params:
    T_max: 300
    eta_min: 1e-6
  
  # Early stopping
  early_stopping_patience: 15
  monitor_metric: "val_iou"  # Metric to monitor
  monitor_mode: "max"  # Maximize the monitored metric
  
  # Checkpointing
  checkpoint_dir: "/Volumes/<catalog>/<schema>/<volume>/<path>/checkpoints/segmentation_segformer"
  save_top_k: 3
  
  # Logging
  log_every_n_steps: 50
  log_dir: "/Volumes/<catalog>/<schema>/<volume>/<path>/logs"
  
  # Distributed training
  distributed: false
  use_gpu: true
  resources_per_worker:
    CPU: 4
    GPU: 1

# MLflow Configuration
mlflow:
  experiment_name: "segmentation_training"
  run_name: "segformer_b0"
  log_model: true
  tags:
    framework: "pytorch_lightning"
    model: "segformer"
    dataset: "ade20k"

# Output Configuration
output:
  results_dir: "/Volumes/<catalog>/<schema>/<volume>/<path>/results/segmentation_segformer"
  save_predictions: true
  visualization:
    save_images: true
    confidence_threshold: 0.5
    max_masks: 20 